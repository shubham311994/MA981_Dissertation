{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4694de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob\n",
    "from typing import Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "import lightgbm as lg\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn_genetic.space import Categorical, Integer, Continuous\n",
    "\n",
    "import sklearn.metrics as m\n",
    "\n",
    "from mne import make_fixed_length_epochs\n",
    "from mne_icalabel import label_components\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "mne.set_config('MNE_BROWSE_RAW_SIZE','20,20')\n",
    "%matplotlib qt\n",
    "mne.viz.set_3d_backend(\"notebook\")\n",
    "plt.rcParams[\"figure.figsize\"] = [20,20]\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0727316",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw2 = mne.io.read_raw_eeglab('PRE_ICA_new_analyses/new_done/40SL_01-100.set', preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f8497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_categories(raw: mne.io.eeglab.eeglab.RawEEGLAB) -> mne.io.eeglab.eeglab.RawEEGLAB:\n",
    "    \"\"\"\n",
    "    Extract the data of different categories from the raw file and return the segregated raw data files.\n",
    "    :param raw:\n",
    "    :return: eyes_open, eyes_close, warm_feel, hot_feel, noise_data\n",
    "    \"\"\"\n",
    "    for each in range(0, 101):\n",
    "\n",
    "        if raw._annotations[each]['description'] == '5':\n",
    "            eyes_open = raw.copy().crop(tmin=raw._annotations[each]['onset'],\n",
    "                                        tmax=raw._annotations[each]['onset'] + 150)\n",
    "        if raw._annotations[each]['description'] == '4':\n",
    "            eyes_close = raw.copy().crop(tmin=raw._annotations[each]['onset'],\n",
    "                                         tmax=raw._annotations[each]['onset'] + 150)\n",
    "        if raw._annotations[each]['description'] == '41':\n",
    "            warm_feel = raw.copy().crop(tmin=raw._annotations[each]['onset'],\n",
    "                                        tmax=raw._annotations[each]['onset'] + 300)\n",
    "        if raw._annotations[each]['description'] == '11':\n",
    "            hot_feel = raw.copy().crop(tmin=raw._annotations[each]['onset'],\n",
    "                                       tmax=raw._annotations[each]['onset'] + 300)\n",
    "        if raw._annotations[each]['description'] == '71':\n",
    "            noise_data = raw.copy().crop(tmin=raw._annotations[each]['onset'],\n",
    "                                         tmax=raw._annotations[each]['onset'] + 300)\n",
    "\n",
    "    return eyes_open, eyes_close, warm_feel, hot_feel, noise_data\n",
    "\n",
    "def filter_data(raw: mne.io.eeglab.eeglab.RawEEGLAB) -> mne.io.eeglab.eeglab.RawEEGLAB:\n",
    "    \"\"\"\n",
    "    Use the band pass filter to filter out the noise and unwanted frequency data from the actual dataset.\n",
    "    :param raw: raw object of the data which needs to be filtered.\n",
    "    :return: raw object with filtered data.\n",
    "    \"\"\"\n",
    "    filtered_data = mne.io.Raw.filter(raw, l_freq=0.5, h_freq=30)\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43508b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = filter_data(raw2)\n",
    "\n",
    "# making the copy of the data\n",
    "# applying ica on the copy of the raw object\n",
    "raw_copy = raw.copy()\n",
    "ica = mne.preprocessing.ICA(n_components=None, random_state=42)\n",
    "ica.fit(raw_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1de0d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e32dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_labels = label_components(raw_copy, ica, method=\"iclabel\")\n",
    "\n",
    "# ICA0 was correctly identified as an eye blink, whereas ICA12 was\n",
    "# also classified as a muscle artifact\n",
    "\n",
    "\n",
    "exclude_index = []\n",
    "for i, each in enumerate(ic_labels['labels']):\n",
    "    if (each=='eye blink') or (each.endswith('noise')):\n",
    "        exclude_index.append(i)\n",
    "\n",
    "ica.apply(raw_copy, exclude = exclude_index)\n",
    "\n",
    "eyes_open, eyes_close, warm_feel, hot_feel, noise_data = extract_data_categories(raw=raw_copy)\n",
    "\n",
    "warm_feel_epochs = make_fixed_length_epochs(warm_feel, duration=1, overlap=0.5)\n",
    "\n",
    "sound_feel_epochs = make_fixed_length_epochs(noise_data, duration=1, overlap=0.5)\n",
    "\n",
    "wf_psd_data, wf_freqs = mne.time_frequency.psd_welch(warm_feel_epochs, fmin=0.5, fmax=50, average='median')\n",
    "\n",
    "sf_psd_data, sf_freqs = mne.time_frequency.psd_welch(sound_feel_epochs, fmin=0.5, fmax=50, average='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "70e7569b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading D:\\Pain_Detection_Dataset\\PRE_ICA_new_analyses\\PRE_ICA_new_analyses\\29BE_01-100.fdt\n",
      "Reading 0 ... 1221739  =      0.000 ...  2443.478 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:5: RuntimeWarning: Data file name in EEG.data (32AC_01-100.fdt) is incorrect, the file name must have changed on disk, using the correct file name (29BE_01-100.fdt).\n",
      "  raw2 = mne.io.read_raw_eeglab(each, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:5: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw2 = mne.io.read_raw_eeglab(each, preload=True)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 63 channels (please be patient, this may take a while)\n",
      "Selecting by non-zero PCA components: 60 components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:13: RuntimeWarning: Using n_components=None (resulting in n_components_=60) may lead to an unstable mixing matrix estimation because the ratio between the largest (62) and smallest (2.5e-05) variances is too large (> 1e6); consider setting n_components=0.999999 or an integer <= 54\n",
      "  ica.fit(raw_copy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA took 702.1s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:15: RuntimeWarning: The provided Raw instance does not seem to be referenced to a common average reference (CAR). ICLabel was designed to classify features extracted from an EEG dataset referenced to a CAR (see the 'set_eeg_reference()' method for Raw and Epochs instances).\n",
      "  ic_labels = label_components(raw_copy, ica, method=\"iclabel\")\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:15: RuntimeWarning: The provided Raw instance is not filtered between 1 and 100 Hz. ICLabel was designed to classify features extracted from an EEG dataset bandpass filtered between 1 and 100 Hz (see the 'filter()' method for Raw and Epochs instances).\n",
      "  ic_labels = label_components(raw_copy, ica, method=\"iclabel\")\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:15: RuntimeWarning: The provided ICA instance was fitted with a 'fastica' algorithm. ICLabel was designed with extended infomax ICA decompositions. To use the extended infomax algorithm, use the 'mne.preprocessing.ICA' instance with the arguments 'ICA(method='infomax', fit_params=dict(extended=True))' (scikit-learn) or 'ICA(method='picard', fit_params=dict(ortho=False, extended=True))' (python-picard).\n",
      "  ic_labels = label_components(raw_copy, ica, method=\"iclabel\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (60 components)\n",
      "    Zeroing out 9 ICA components\n",
      "    Projecting back using 63 PCA components\n",
      "Not setting metadata\n",
      "599 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "599 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 599 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Effective window size : 0.512 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 599 events and 500 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   26.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   26.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Effective window size : 0.512 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   22.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   22.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading D:\\Pain_Detection_Dataset\\PRE_ICA_new_analyses\\PRE_ICA_new_analyses\\30CK_01-100.fdt\n",
      "Reading 0 ... 1331859  =      0.000 ...  2663.718 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:   10.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 63 channels (please be patient, this may take a while)\n",
      "Selecting by non-zero PCA components: 60 components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:13: RuntimeWarning: Using n_components=None (resulting in n_components_=60) may lead to an unstable mixing matrix estimation because the ratio between the largest (55) and smallest (3.2e-05) variances is too large (> 1e6); consider setting n_components=0.999999 or an integer <= 56\n",
      "  ica.fit(raw_copy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA took 242.4s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:15: RuntimeWarning: The provided Raw instance does not seem to be referenced to a common average reference (CAR). ICLabel was designed to classify features extracted from an EEG dataset referenced to a CAR (see the 'set_eeg_reference()' method for Raw and Epochs instances).\n",
      "  ic_labels = label_components(raw_copy, ica, method=\"iclabel\")\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:15: RuntimeWarning: The provided Raw instance is not filtered between 1 and 100 Hz. ICLabel was designed to classify features extracted from an EEG dataset bandpass filtered between 1 and 100 Hz (see the 'filter()' method for Raw and Epochs instances).\n",
      "  ic_labels = label_components(raw_copy, ica, method=\"iclabel\")\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:15: RuntimeWarning: The provided ICA instance was fitted with a 'fastica' algorithm. ICLabel was designed with extended infomax ICA decompositions. To use the extended infomax algorithm, use the 'mne.preprocessing.ICA' instance with the arguments 'ICA(method='infomax', fit_params=dict(extended=True))' (scikit-learn) or 'ICA(method='picard', fit_params=dict(ortho=False, extended=True))' (python-picard).\n",
      "  ic_labels = label_components(raw_copy, ica, method=\"iclabel\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (60 components)\n",
      "    Zeroing out 8 ICA components\n",
      "    Projecting back using 63 PCA components\n",
      "Not setting metadata\n",
      "599 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "599 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 599 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Effective window size : 0.512 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 599 events and 500 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   30.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   30.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Effective window size : 0.512 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   36.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   36.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading D:\\Pain_Detection_Dataset\\PRE_ICA_new_analyses\\PRE_ICA_new_analyses\\38JC_01-100.fdt\n",
      "Reading 0 ... 1088699  =      0.000 ...  2177.398 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 63 channels (please be patient, this may take a while)\n",
      "Selecting by non-zero PCA components: 63 components\n",
      "Fitting ICA took 163.2s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:15: RuntimeWarning: The provided Raw instance does not seem to be referenced to a common average reference (CAR). ICLabel was designed to classify features extracted from an EEG dataset referenced to a CAR (see the 'set_eeg_reference()' method for Raw and Epochs instances).\n",
      "  ic_labels = label_components(raw_copy, ica, method=\"iclabel\")\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:15: RuntimeWarning: The provided Raw instance is not filtered between 1 and 100 Hz. ICLabel was designed to classify features extracted from an EEG dataset bandpass filtered between 1 and 100 Hz (see the 'filter()' method for Raw and Epochs instances).\n",
      "  ic_labels = label_components(raw_copy, ica, method=\"iclabel\")\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:15: RuntimeWarning: The provided ICA instance was fitted with a 'fastica' algorithm. ICLabel was designed with extended infomax ICA decompositions. To use the extended infomax algorithm, use the 'mne.preprocessing.ICA' instance with the arguments 'ICA(method='infomax', fit_params=dict(extended=True))' (scikit-learn) or 'ICA(method='picard', fit_params=dict(ortho=False, extended=True))' (python-picard).\n",
      "  ic_labels = label_components(raw_copy, ica, method=\"iclabel\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (63 components)\n",
      "    Zeroing out 4 ICA components\n",
      "    Projecting back using 63 PCA components\n",
      "Not setting metadata\n",
      "599 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "599 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 599 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Effective window size : 0.512 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 599 events and 500 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   51.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   51.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Effective window size : 0.512 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   51.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   51.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading D:\\Pain_Detection_Dataset\\PRE_ICA_new_analyses\\PRE_ICA_new_analyses\\41IA_01-100.fdt\n",
      "Reading 0 ... 1087939  =      0.000 ...  2175.878 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:    6.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 63 channels (please be patient, this may take a while)\n",
      "Selecting by non-zero PCA components: 47 components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:13: RuntimeWarning: Using n_components=None (resulting in n_components_=47) may lead to an unstable mixing matrix estimation because the ratio between the largest (54) and smallest (6.2e-06) variances is too large (> 1e6); consider setting n_components=0.999999 or an integer <= 24\n",
      "  ica.fit(raw_copy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA took 204.9s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:15: RuntimeWarning: The provided Raw instance does not seem to be referenced to a common average reference (CAR). ICLabel was designed to classify features extracted from an EEG dataset referenced to a CAR (see the 'set_eeg_reference()' method for Raw and Epochs instances).\n",
      "  ic_labels = label_components(raw_copy, ica, method=\"iclabel\")\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:15: RuntimeWarning: The provided Raw instance is not filtered between 1 and 100 Hz. ICLabel was designed to classify features extracted from an EEG dataset bandpass filtered between 1 and 100 Hz (see the 'filter()' method for Raw and Epochs instances).\n",
      "  ic_labels = label_components(raw_copy, ica, method=\"iclabel\")\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_20416\\466159812.py:15: RuntimeWarning: The provided ICA instance was fitted with a 'fastica' algorithm. ICLabel was designed with extended infomax ICA decompositions. To use the extended infomax algorithm, use the 'mne.preprocessing.ICA' instance with the arguments 'ICA(method='infomax', fit_params=dict(extended=True))' (scikit-learn) or 'ICA(method='picard', fit_params=dict(ortho=False, extended=True))' (python-picard).\n",
      "  ic_labels = label_components(raw_copy, ica, method=\"iclabel\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (47 components)\n",
      "    Zeroing out 8 ICA components\n",
      "    Projecting back using 63 PCA components\n",
      "Not setting metadata\n",
      "599 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "599 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 599 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Effective window size : 0.512 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 599 events and 500 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   23.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   23.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.512 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   22.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   22.8s finished\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "p=0\n",
    "for each in glob.glob('D://Pain_Detection_Dataset//PRE_ICA_new_analyses//PRE_ICA_new_analyses//*.set'):\n",
    "    \n",
    "    raw2 = mne.io.read_raw_eeglab(each, preload=True)\n",
    "\n",
    "    raw = filter_data(raw2)\n",
    "\n",
    "    # making the copy of the data\n",
    "    # applying ica on the copy of the raw object\n",
    "    raw_copy = raw.copy()\n",
    "    ica = mne.preprocessing.ICA(n_components=None, random_state=42)\n",
    "    ica.fit(raw_copy)\n",
    "\n",
    "    ic_labels = label_components(raw_copy, ica, method=\"iclabel\")\n",
    "\n",
    "    # ICA0 was correctly identified as an eye blink, whereas ICA12 was\n",
    "    # also classified as a muscle artifact\n",
    "\n",
    "\n",
    "    exclude_index = []\n",
    "    for i, each in enumerate(ic_labels['labels']):\n",
    "        if (each=='eye blink') or (each.endswith('noise')):\n",
    "            exclude_index.append(i)\n",
    "\n",
    "    ica.apply(raw_copy, exclude = exclude_index)\n",
    "\n",
    "    eyes_open, eyes_close, warm_feel, hot_feel, noise_data = extract_data_categories(raw=raw_copy)\n",
    "\n",
    "    warm_feel_epochs = make_fixed_length_epochs(warm_feel, duration=1, overlap=0.5)\n",
    "\n",
    "    sound_feel_epochs = make_fixed_length_epochs(noise_data, duration=1, overlap=0.5)\n",
    "\n",
    "    wf_psd_data, wf_freqs = mne.time_frequency.psd_welch(warm_feel_epochs, fmin=0.5, fmax=50, average='median')\n",
    "\n",
    "    sf_psd_data, sf_freqs = mne.time_frequency.psd_welch(sound_feel_epochs, fmin=0.5, fmax=50, average='median')\n",
    "\n",
    "    warm_feel_data = pd.DataFrame(wf_psd_data.reshape(wf_psd_data.shape[0],-1))\n",
    "    sound_feel_data = pd.DataFrame(sf_psd_data.reshape(sf_psd_data.shape[0],-1))\n",
    "\n",
    "    warm_feel_data['target'] = np.zeros(shape=warm_feel_data.shape[0], dtype='int')\n",
    "\n",
    "    sound_feel_data['target'] = np.full(sound_feel_data.shape[0],1, dtype='int')\n",
    "\n",
    "    merged_data = pd.concat([warm_feel_data,sound_feel_data])\n",
    "\n",
    "    X = merged_data.drop(columns=['target']).values\n",
    "    y = merged_data['target'].values    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(merged_data.drop(columns=['target']), merged_data['target'], \n",
    "                                                        test_size=0.2, random_state=42, stratify=merged_data['target'])\n",
    "\n",
    "    res_dict = warm_vs_sound(warm_feel_data, sound_feel_data, participant_number=p)\n",
    "    p=p+1\n",
    "    file_name = each.split('.')[0][57:]\n",
    "    pd.DataFrame(res_dict).to_csv(f'wf_sf/{p}_wf_sf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "41f3be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Any\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def check_file_exists(file_path: str) -> bool:\n",
    "    \"\"\"Check if the file exists in a particular path.\n",
    "    :param:: file_path: file path in string format.\n",
    "    :return: boolean\n",
    "    \"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    check_file_exist = file_path.is_file()\n",
    "\n",
    "    return check_file_exist\n",
    "\n",
    "\n",
    "def get_file_list_from_path(file_path: Path) -> Tuple[list, list]:\n",
    "    \"\"\"\n",
    "    Get the list of files in the directory with particular format\n",
    "    :param:: Path object of the file directory path.\n",
    "    :return list of set files and list of fdt files.\n",
    "    \"\"\"\n",
    "    list_of_fdt = glob.glob(f'{file_path}/*.fdt')\n",
    "    list_of_set = glob.glob(f'{file_path}/*.set')\n",
    "\n",
    "    return list_of_fdt, list_of_set\n",
    "\n",
    "\n",
    "def compute_accuracy(y_actual: np.ndarray, y_predicted: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the accuracy for the given true and predicted values.\n",
    "    :param: y_actual: The actual value of y variable or target.\n",
    "    :param: y_predicted: The predicted value of y variable or target.\n",
    "    :return: accuracy percentage score of the values.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_actual, y_predicted)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def compute_classification_report(y_actual: np.ndarray, y_predicted: np.ndarray):\n",
    "    \"\"\"\n",
    "    Compute the classification report for the given true and predicted values.\n",
    "    :param: y_actual: The actual value of y variable or target.\n",
    "    :param: y_predicted: The predicted value of y variable or target.\n",
    "    :return: the classification report with precision and recall.\n",
    "    \"\"\"\n",
    "\n",
    "    cf_report = classification_report(y_actual, y_predicted)\n",
    "\n",
    "    return cf_report\n",
    "\n",
    "\n",
    "def compute_sensitivity_specificity(y_actual: np.ndarray, y_predicted: np.ndarray) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Compute the sensitivity and specificity using actual and predicted target values\n",
    "    :param: y_actual: The actual value of y variable or target.\n",
    "    :param: y_predicted: The predicted value of y variable or target.\n",
    "    :return: sensitivity and specificity\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def apply_stratified_cv(model_object, x: np.ndarray, y: np.ndarray):\n",
    "    \"\"\"\n",
    "    Divide the data into pre-defined splits and used the passed model_object to train and compute accuracy and\n",
    "    classification_report.\n",
    "    :param: model_object: model object of particular model applied on the dataset.\n",
    "    :param: X: value or the features\n",
    "    :param: y: value or the targets\n",
    "    :return: list of accuracy value in decimals for all the splits.\n",
    "    \"\"\"\n",
    "    accuracy_value = []\n",
    "    f1_score_list = []\n",
    "    sensitivity_list = []\n",
    "    specificity_list = []\n",
    "    sfk = StratifiedKFold(n_splits=10)\n",
    "    for train_index, test_index in sfk.split(x, y):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model_object.fit(x_train, y_train)\n",
    "        predictions = model_object.predict(x_test)\n",
    "        accuracy_value.append(compute_accuracy(y_test, predictions))\n",
    "        f1_score, sensitivity, specificity = accuracy_metrics(y_test, predictions)\n",
    "        f1_score_list.append(f1_score)\n",
    "        sensitivity_list.append(sensitivity)\n",
    "        specificity_list.append(specificity)\n",
    "\n",
    "    return accuracy_value, f1_score_list, sensitivity_list, specificity_list\n",
    "\n",
    "\n",
    "def accuracy_metrics(y_test, predictions):\n",
    "    conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "    TP = conf_matrix[1][1]\n",
    "    TN = conf_matrix[0][0]\n",
    "    FP = conf_matrix[0][1]\n",
    "    FN = conf_matrix[1][0]\n",
    "\n",
    "    # calculate accuracy\n",
    "    conf_accuracy = (float(TP + TN) / float(TP + TN + FP + FN))\n",
    "\n",
    "    # calculate mis-classification\n",
    "    conf_misclassification = 1 - conf_accuracy\n",
    "\n",
    "    # calculate the sensitivity\n",
    "    conf_sensitivity = (TP / float(TP + FN))\n",
    "    # calculate the specificity\n",
    "    conf_specificity = (TN / float(TN + FP))\n",
    "\n",
    "    # calculate precision\n",
    "    conf_precision = (TN / float(TN + FP))\n",
    "    # calculate f_1 score\n",
    "    conf_f1 = 2 * ((conf_precision * conf_sensitivity) / (conf_precision + conf_sensitivity))\n",
    "\n",
    "    return conf_f1, conf_sensitivity, conf_specificity\n",
    "\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mne_icalabel import label_components\n",
    "from mne import make_fixed_length_epochs\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def read_file(path: str) -> mne.io.eeglab.eeglab.RawEEGLAB:\n",
    "    \"\"\"\n",
    "    Read the EEG data from the given path of fdt and set.\n",
    "    :param: path: path of the data file in string format.\n",
    "    :return: raw object of type mne.io.eeglab.eeglab.RawEEGLAB\n",
    "    \"\"\"\n",
    "    raw = mne.io.read_raw_eeglab(path, preload=True)\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "def extract_data_categories(raw: mne.io.eeglab.eeglab.RawEEGLAB):\n",
    "    \"\"\"\n",
    "    Extract the data of different categories from the raw file and return the segregated raw data files.\n",
    "    :param raw:\n",
    "    :return: eyes_open, eyes_close, warm_feel, hot_feel, noise_data\n",
    "    \"\"\"\n",
    "    global eyes_open, eyes_close, warm_feel, hot_feel, noise_data\n",
    "    for each in range(0, 101):\n",
    "\n",
    "        if raw._annotations[each]['description'] == '5':\n",
    "            eyes_open = raw.copy().crop(tmin=raw._annotations[each]['onset'],\n",
    "                                        tmax=raw._annotations[each]['onset'] + 150)\n",
    "        if raw._annotations[each]['description'] == '4':\n",
    "            eyes_close = raw.copy().crop(tmin=raw._annotations[each]['onset'],\n",
    "                                         tmax=raw._annotations[each]['onset'] + 150)\n",
    "        if raw._annotations[each]['description'] == '41':\n",
    "            warm_feel = raw.copy().crop(tmin=raw._annotations[each]['onset'],\n",
    "                                        tmax=raw._annotations[each]['onset'] + 300)\n",
    "        if raw._annotations[each]['description'] == '11':\n",
    "            hot_feel = raw.copy().crop(tmin=raw._annotations[each]['onset'],\n",
    "                                       tmax=raw._annotations[each]['onset'] + 300)\n",
    "        if raw._annotations[each]['description'] == '71':\n",
    "            noise_data = raw.copy().crop(tmin=raw._annotations[each]['onset'],\n",
    "                                         tmax=raw._annotations[each]['onset'] + 300)\n",
    "\n",
    "    return eyes_open, eyes_close, warm_feel, hot_feel, noise_data\n",
    "\n",
    "\n",
    "def filter_data(raw: mne.io.eeglab.eeglab.RawEEGLAB) -> mne.io.eeglab.eeglab.RawEEGLAB:\n",
    "    \"\"\"\n",
    "    Use the band pass filter to filter out the noise and unwanted frequency data from the actual dataset.\n",
    "    :param: raw: raw object of the data which needs to be filtered.\n",
    "    :return: raw object with filtered data.\n",
    "    \"\"\"\n",
    "    filtered_data = mne.io.Raw.filter(raw, l_freq=0.5, h_freq=30)\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def standardize_raw_data(raw: mne.io.eeglab.eeglab.RawEEGLAB) -> mne.io.eeglab.eeglab.RawEEGLAB:\n",
    "    \"\"\"\n",
    "    Use the standardization method to standardise the raw signals with z-score method.\n",
    "    :param: raw: raw object of the data to be standardized.\n",
    "    :return: raw object with standardized values.\n",
    "    \"\"\"\n",
    "    raw = raw.apply_function(lambda x: (x - np.mean(x) / np.std(x)))\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "def get_ica_labels(raw: mne.io.eeglab.eeglab.RawEEGLAB, ica: mne.preprocessing.ica.ICA) -> dict:\n",
    "    \"\"\"\n",
    "    USe the raw data to get the labels from the ica obj\n",
    "    :param: raw: get the labels of ICA fit raw object\n",
    "    :param: ica: ica object of the fitted raw object.\n",
    "    :return: dictionary containing the labels for ica components\n",
    "    \"\"\"\n",
    "    ic_labels = label_components(raw, ica, method=\"iclabel\")\n",
    "\n",
    "    return ic_labels\n",
    "\n",
    "\n",
    "def fit_ica(raw: mne.io.eeglab.eeglab.RawEEGLAB) -> mne.preprocessing.ica.ICA:\n",
    "    \"\"\"\n",
    "    Fit the ica on the raw object to obtain the ica components.\n",
    "    :param: raw: raw object containing the data.\n",
    "    :return: ica object after it is fitted on the raw data.\n",
    "    \"\"\"\n",
    "    raw = filter_data(raw=raw)\n",
    "    ica = mne.preprocessing.ICA(n_components=0.99, random_state=42)\n",
    "    ica.fit(raw)\n",
    "\n",
    "    return ica\n",
    "\n",
    "\n",
    "def get_label_index_to_exclude(ica_labels: dict) -> list:\n",
    "    \"\"\"\n",
    "    Find the ICA components indexes which are to be excluded during artifact repair.\n",
    "    :param: ica_labels:\n",
    "    :return: exclude_index list\n",
    "    \"\"\"\n",
    "    exclude_index = []\n",
    "    for i, each in enumerate(ica_labels['labels']):\n",
    "        if (each == 'eye blink') or (each.endswith('noise')):\n",
    "            exclude_index.append(i)\n",
    "\n",
    "    return exclude_index\n",
    "\n",
    "\n",
    "def repair_ica_artifact(raw: mne.io.eeglab.eeglab.RawEEGLAB) -> mne.io.eeglab.eeglab.RawEEGLAB:\n",
    "    \"\"\"\n",
    "    Repair the raw object artifact using the ica\n",
    "    :param: raw: raw object to be repaired\n",
    "    :return: repaired raw object with removed noises.\n",
    "    \"\"\"\n",
    "    ica = fit_ica(raw=raw)\n",
    "    ic_labels = get_ica_labels(raw=raw, ica=ica)\n",
    "    exclude_index = get_label_index_to_exclude(ica_labels=ic_labels)\n",
    "    raw = ica.apply(raw, exclude=exclude_index)\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "def convert_epoch_to_frequency_vs_time(epoch_object: mne.epochs.Epochs) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert the epochs into times vs frequency using psd_welch method.\n",
    "    :param epoch_object:\n",
    "    :return: numpy array of 3 dimensions with (n_epochs, n_channels, n_freq)\n",
    "    \"\"\"\n",
    "\n",
    "    epoch_array, _frequencies = mne.time_frequency.psd_welch(epoch_object, fmin=0.5, fmax=30, average='median')\n",
    "\n",
    "    return epoch_array\n",
    "\n",
    "\n",
    "def create_dataframe_from_epoch(epoch_data: np.ndarray, label_value: int):\n",
    "    \"\"\"\n",
    "    Convert the numpy data into dataframe and add target label to it.\n",
    "    :param: epoch_data: numpy array obtained from the epoch conversion of raw data.\n",
    "    :param: label_value: label value to be used for the particular type of data\n",
    "    :return: pandas dataframe containing the feature and target value.\n",
    "    \"\"\"\n",
    "\n",
    "    data_set = pd.DataFrame(epoch_data.reshape(epoch_data.shape[0], -1))\n",
    "    data_set['target'] = np.full(data_set.shape[0], label_value, dtype='int')\n",
    "\n",
    "    return data_set\n",
    "\n",
    "\n",
    "def create_epoch_data(raw: mne.io.eeglab.eeglab.RawEEGLAB, duration: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get the epoch of the raw object using the fixed length epoch method.\n",
    "    :param: raw: raw object containing the data.\n",
    "    :param: duration: duration of the epoch to be used.\n",
    "    :return: 3 dimensional array containing the data of the raw object.\n",
    "    \"\"\"\n",
    "    epoch_data = make_fixed_length_epochs(raw, duration=duration, preload=True, overlap=float(duration / 2))\n",
    "    epoch_frequency_data = convert_epoch_to_frequency_vs_time(epoch_data)\n",
    "\n",
    "    return epoch_frequency_data\n",
    "\n",
    "\n",
    "def combine_dataframes(dataframe1, dataframe2):\n",
    "    \"\"\"\n",
    "    Merge the two dataframes into one\n",
    "    :param: dataframe1: dataframe of one type with label.\n",
    "    :param: dataframe2: dataframe of another type with label.\n",
    "    \"\"\"\n",
    "    merged_dataframe = pd.concat([dataframe1, dataframe2])\n",
    "\n",
    "    return merged_dataframe\n",
    "\n",
    "\n",
    "def calculate_duration(raw: mne.io.eeglab.eeglab.RawEEGLAB) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the duration of the raw object reading.\n",
    "    :param: raw object\n",
    "    \"\"\"\n",
    "    scan_duration = raw._data.shape[1] / raw.info['sfreq']\n",
    "\n",
    "    return scan_duration\n",
    "\n",
    "\n",
    "metrics_list_wf_sf = []\n",
    "\n",
    "lg_clf = lg.LGBMClassifier(device=\"gpu\", colsample_bytree=0.6798358579930577,\n",
    "                        learning_rate=0.00919045768056308, n_estimators=600,\n",
    "                        num_leaves=10, objective='binary')\n",
    "lda_clf = LinearDiscriminantAnalysis(shrinkage=0.21797193476378346, solver='lsqr')\n",
    "knn_clf = KNeighborsClassifier(metric='manhattan', n_neighbors=8)\n",
    "\n",
    "PATH = 'D:\\\\Pain_Detection_Dataset\\\\PRE_ICA_new_analyses\\\\faulty\\\\'\n",
    "\n",
    "\n",
    "def warm_vs_sound(warm_dataframe, sound_dataframe, participant_number: int):\n",
    "    \"\"\"\n",
    "    Compare warm vs sound pain by fitting machine learning algorithm and computing accuracy and other measures for each\n",
    "    subject.\n",
    "    :return: results of each subject in dictionary\n",
    "    \"\"\"\n",
    "    result_dict = {'participant_id': participant_number, 'lightgbm_accuracy': [], 'lda_accuracy': [],\n",
    "                   'knn_accuracy': [], 'lightgbm_f1_score': [], 'lda_f1_score': [], 'knn_f1_score': [],\n",
    "                   'lightgbm_sensitivity': [], 'lda_sensitivity': [], 'knn_sensitivity': [], 'lightgbm_specificity': [],\n",
    "                   'lda_specificity': [], 'knn_specificity': []}\n",
    "    data = combine_dataframes(warm_dataframe, sound_dataframe)\n",
    "    x = data.drop(columns=['target']).values\n",
    "    y = data['target'].values\n",
    "    for each in [lg_clf, lda_clf, knn_clf]:\n",
    "        accuracy_list, f1_score_list, sensitivity_list, specificity_list = apply_stratified_cv(each, x=x, y=y)\n",
    "        if type(each).__name__ == 'LGBMClassifier':\n",
    "            result_dict['lightgbm_accuracy'] = accuracy_list\n",
    "            result_dict['lightgbm_f1_score'] = f1_score_list\n",
    "            result_dict['lightgbm_sensitivity'] = sensitivity_list\n",
    "            result_dict['lightgbm_specificity'] = specificity_list\n",
    "        if type(each).__name__ == 'LinearDiscriminantAnalysis':\n",
    "            result_dict['lda_accuracy'] = accuracy_list\n",
    "            result_dict['lda_f1_score'] = f1_score_list\n",
    "            result_dict['lda_sensitivity'] = sensitivity_list\n",
    "            result_dict['lda_specificity'] = specificity_list\n",
    "        if type(each).__name__ == 'KNeighborsClassifier':\n",
    "            result_dict['knn_accuracy'] = accuracy_list\n",
    "            result_dict['knn_f1_score'] = f1_score_list\n",
    "            result_dict['knn_sensitivity'] = sensitivity_list\n",
    "            result_dict['knn_specificity'] = specificity_list\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "\n",
    "def main(file_path: Path):\n",
    "    \"\"\"\n",
    "    Run all the preprocessing and epoch conversion. Convert the epochs to dataframe and then use it for Machine Learning\n",
    "    :param: file_path: Path of the files where the data is stored.\n",
    "    \"\"\"\n",
    "    list_of_fdt_file_path, list_of_set_file_path = get_file_list_from_path(file_path=file_path)\n",
    "    participant = 0\n",
    "    if list_of_fdt_file_path and list_of_set_file_path:\n",
    "        try:\n",
    "            if len(list_of_fdt_file_path) == len(list_of_set_file_path):\n",
    "                for fdt_file, set_file in zip(list_of_fdt_file_path, list_of_set_file_path):\n",
    "                    if (check_file_exists(fdt_file)) & (check_file_exists(set_file)):\n",
    "                        raw = read_file(set_file)\n",
    "                        if calculate_duration(raw) < 2200:\n",
    "                            continue\n",
    "                        else:\n",
    "                            repaired_raw = repair_ica_artifact(raw=raw)\n",
    "                            eyes_open_raw, eyes_close_raw, warm_feel_raw, hot_feel_raw, sound_feel_raw = \\\n",
    "                                extract_data_categories(repaired_raw)\n",
    "                            hot_feel_epoch = create_epoch_data(raw=hot_feel_raw, duration=1)\n",
    "                            warm_feel_epoch = create_epoch_data(raw=warm_feel_raw, duration=1)\n",
    "                            metrics_list_wf_hf.append(\n",
    "                                warm_vs_hot(create_dataframe_from_epoch(warm_feel_epoch, label_value=0),\n",
    "                                            create_dataframe_from_epoch(hot_feel_epoch, label_value=1),\n",
    "                                            participant_number=participant))\n",
    "                            print(f'Participant #: {participant + 1}')\n",
    "                            participant += 1\n",
    "                            accuracy_wf_hf = pd.DataFrame(metrics_list_wf_hf)\n",
    "                            accuracy_wf_hf.to_csv(Path(f'{PATH}\\\\hf_wf\\\\{participant}_accuracy_wf_hf.csv'))\n",
    "            else:\n",
    "                raise SizeNotMatched({\n",
    "                    f\"The number of FDT and SET files is not same fdt is {len(list_of_fdt_file_path)} \\\n",
    "                     != set is {len(list_of_set_file_path)}\"})\n",
    "        except FileNotFoundError as fe:\n",
    "            fe.strerror = f\"Either fdt_file or set_file doesn't exist\"\n",
    "            raise fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81ca3962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69       120\n",
      "           1       0.69      0.78      0.73       120\n",
      "\n",
      "    accuracy                           0.71       240\n",
      "   macro avg       0.72      0.71      0.71       240\n",
      "weighted avg       0.72      0.71      0.71       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "print(m.classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9e42699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       120\n",
      "           1       0.99      0.97      0.98       120\n",
      "\n",
      "    accuracy                           0.98       240\n",
      "   macro avg       0.98      0.98      0.98       240\n",
      "weighted avg       0.98      0.98      0.98       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "lda_pred = lda.predict(X_test)\n",
    "\n",
    "print(m.classification_report(y_test, lda_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "620195ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       120\n",
      "           1       1.00      1.00      1.00       120\n",
      "\n",
      "    accuracy                           1.00       240\n",
      "   macro avg       1.00      1.00      1.00       240\n",
      "weighted avg       1.00      1.00      1.00       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lg_clf = lg.LGBMClassifier(device=\"gpu\")\n",
    "lg_clf.fit(X_train, y_train)\n",
    "pred = lg_clf.predict(X_test)\n",
    "print(m.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46a762b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfk = StratifiedKFold(n_splits=10)\n",
    "lg_clf = lg.LGBMClassifier(device=\"gpu\")\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "31f4397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridParams = {\n",
    "    'learning_rate': np.random.uniform(0.005, 0.01, 5),\n",
    "    'n_estimators': range(300, 900, 300),\n",
    "    'num_leaves': range(9,12), # large num_leaves helps improve accuracy but might lead to over-fitting\n",
    "    'boosting_type' : ['gbdt', 'dart'], # for better accuracy -> try dart\n",
    "    'objective' : ['binary'],\n",
    "    'colsample_bytree' : np.random.uniform(0.65, 0.7, 3)\n",
    "    }\n",
    "\n",
    "gs_lgbm = GridSearchCV(estimator=lg_clf, param_grid=gridParams, cv=sfk)\n",
    "gs_lgbm.fit(X,y)\n",
    "\n",
    "gs_lgbm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "551de531",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': range(1,16),\n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'metric': ['euclidean', 'manhattan']              \n",
    "             }\n",
    "\n",
    "gs_knn = GridSearchCV(estimator=knn, param_grid=param_grid, cv=sfk)\n",
    "gs_knn.fit(X,y)\n",
    "\n",
    "gs_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843965a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_params = {'shrinkage': np.random.uniform(0.1,1,10),'solver':['svd', 'lsqr', 'eigen']}\n",
    "\n",
    "gs_lda = GridSearchCV(estimator=lda, param_grid=lda_params, cv=sfk, scoring='accuracy')\n",
    "gs_lda.fit(X,y)\n",
    "\n",
    "gs_lda.best_estimator_\n",
    "\n",
    "gs_lda.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666376e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfk = StratifiedKFold(n_splits=5)\n",
    "lg_clf = lg.LGBMClassifier(device=\"gpu\")\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "accuracy_dictonary_hf_wf = {'lightgbm':[], 'lda':[], 'knn':[]}\n",
    "for train_index, test_index in sfk.split(X,y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    lg_clf.fit(X_train, y_train)\n",
    "    lg_pred = lg_clf.predict(X_test)\n",
    "    accuracy_dictonary_hf_wf['lightgbm'].append(m.accuracy_score(y_test, lg_pred))\n",
    "    lda.fit(X_train, y_train)\n",
    "    lda_pred = lda.predict(X_test)\n",
    "    accuracy_dictonary_hf_wf['lda'].append(m.accuracy_score(y_test, lda_pred))\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn_pred = knn.predict(X_test)\n",
    "    accuracy_dictonary_hf_wf['knn'].append(m.accuracy_score(y_test, knn_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
